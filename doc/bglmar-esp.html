<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="José Mauricio Gómez Julián" />


<title>Detalles Metodológicos del Modelo GLM Bayesiano con Estructura AR(1)</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>







<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore"><strong>Detalles Metodológicos del Modelo
GLM Bayesiano con Estructura AR(1)</strong></h1>
<h4 class="author">José Mauricio Gómez Julián</h4>
<h4 class="date">septiembre 2025</h4>


<div id="TOC">
<ul>
<li><a href="#marco-bayesiano-para-modelado-de-series-temporales-con-estructura-autorregresiva" id="toc-marco-bayesiano-para-modelado-de-series-temporales-con-estructura-autorregresiva"><strong>Marco
Bayesiano para Modelado de Series Temporales con Estructura
Autorregresiva</strong></a>
<ul>
<li><a href="#especificaci%C3%B3n-del-modelo-bayesiano-con-ar1" id="toc-especificación-del-modelo-bayesiano-con-ar1"><strong>Especificación
del Modelo Bayesiano con AR(1)</strong></a>
<ul>
<li><a href="#estructura-del-modelo-completo" id="toc-estructura-del-modelo-completo"><strong>Estructura del Modelo
Completo</strong></a></li>
<li><a href="#modelo-base-de-referencia" id="toc-modelo-base-de-referencia"><strong>Modelo Base de
Referencia</strong></a></li>
<li><a href="#especificaci%C3%B3n-de-priors" id="toc-especificación-de-priors"><strong>Especificación de
Priors</strong></a></li>
</ul></li>
<li><a href="#validaci%C3%B3n-cruzada-temporal-con-leave-future-out-lfo" id="toc-validación-cruzada-temporal-con-leave-future-out-lfo"><strong>Validación
Cruzada Temporal con Leave-Future-Out (LFO)</strong></a>
<ul>
<li><a href="#implementaci%C3%B3n-del-rolling-origin-con-ventana-deslizante" id="toc-implementación-del-rolling-origin-con-ventana-deslizante"><strong>Implementación
del Rolling-Origin con Ventana Deslizante</strong></a></li>
<li><a href="#criterios-de-evaluaci%C3%B3n-predictiva" id="toc-criterios-de-evaluación-predictiva"><strong>Criterios de
Evaluación Predictiva</strong></a></li>
<li><a href="#criterio-de-victoria-por-fold" id="toc-criterio-de-victoria-por-fold"><strong>Criterio de Victoria por
Fold</strong></a></li>
</ul></li>
<li><a href="#inferencia-bayesiana-con-hamiltonian-monte-carlo" id="toc-inferencia-bayesiana-con-hamiltonian-monte-carlo"><strong>Inferencia
Bayesiana con Hamiltonian Monte Carlo</strong></a>
<ul>
<li><a href="#configuraci%C3%B3n-del-muestreador-nuts" id="toc-configuración-del-muestreador-nuts"><strong>Configuración del
Muestreador NUTS</strong></a></li>
<li><a href="#diagn%C3%B3sticos-de-convergencia" id="toc-diagnósticos-de-convergencia"><strong>Diagnósticos de
Convergencia</strong></a></li>
</ul></li>
<li><a href="#determinaci%C3%B3n-de-estabilidad-temporal-y-soporte" id="toc-determinación-de-estabilidad-temporal-y-soporte"><strong>Determinación
de Estabilidad Temporal y Soporte</strong></a>
<ul>
<li><a href="#m%C3%A9trica-de-soporte" id="toc-métrica-de-soporte"><strong>Métrica de Soporte</strong></a></li>
<li><a href="#umbrales-de-robustez" id="toc-umbrales-de-robustez"><strong>Umbrales de
Robustez</strong></a></li>
<li><a href="#interpretaci%C3%B3n-del-soporte" id="toc-interpretación-del-soporte"><strong>Interpretación del
Soporte</strong></a></li>
</ul></li>
<li><a href="#an%C3%A1lisis-comparativo-con-metodolog%C3%ADa-ecm-mars" id="toc-análisis-comparativo-con-metodología-ecm-mars"><strong>Análisis
Comparativo con Metodología ECM-MARS</strong></a>
<ul>
<li><a href="#diferencias-fundamentales" id="toc-diferencias-fundamentales"><strong>Diferencias
Fundamentales</strong></a></li>
<li><a href="#ventajas-del-enfoque-bayesiano" id="toc-ventajas-del-enfoque-bayesiano"><strong>Ventajas del Enfoque
Bayesiano</strong></a></li>
<li><a href="#limitaciones-relativas" id="toc-limitaciones-relativas"><strong>Limitaciones
Relativas</strong></a></li>
</ul></li>
<li><a href="#implementaci%C3%B3n-t%C3%A9cnica-y-optimizaciones" id="toc-implementación-técnica-y-optimizaciones"><strong>Implementación
Técnica y Optimizaciones</strong></a>
<ul>
<li><a href="#gesti%C3%B3n-de-memoria-y-paralelizaci%C3%B3n" id="toc-gestión-de-memoria-y-paralelización"><strong>Gestión de Memoria
y Paralelización</strong></a></li>
<li><a href="#manejo-de-casos-degenerados" id="toc-manejo-de-casos-degenerados"><strong>Manejo de Casos
Degenerados</strong></a></li>
</ul></li>
<li><a href="#pseudoc%C3%B3digo-del-pipeline-completo" id="toc-pseudocódigo-del-pipeline-completo"><strong>Pseudocódigo del
Pipeline Completo</strong></a></li>
<li><a href="#notas-t%C3%A9cnicas-y-consideraciones-especiales" id="toc-notas-técnicas-y-consideraciones-especiales"><strong>Notas
Técnicas y Consideraciones Especiales</strong></a>
<ul>
<li><a href="#escalamiento-y-estabilidad-num%C3%A9rica" id="toc-escalamiento-y-estabilidad-numérica"><strong>Escalamiento y
Estabilidad Numérica</strong></a></li>
<li><a href="#interpretaci%C3%B3n-de-m%C3%A9tricas-negativas" id="toc-interpretación-de-métricas-negativas"><strong>Interpretación de
Métricas Negativas</strong></a></li>
<li><a href="#extensiones-potenciales" id="toc-extensiones-potenciales"><strong>Extensiones
Potenciales</strong></a></li>
</ul></li>
<li><a href="#conclusiones-metodol%C3%B3gicas" id="toc-conclusiones-metodológicas"><strong>Conclusiones
Metodológicas</strong></a></li>
</ul></li>
</ul>
</div>

<div id="marco-bayesiano-para-modelado-de-series-temporales-con-estructura-autorregresiva" class="section level1">
<h1><strong>Marco Bayesiano para Modelado de Series Temporales con
Estructura Autorregresiva</strong></h1>
<p>El presente documento detalla la metodología implementada para el
análisis de relaciones causales entre variables de producción y
circulación mediante un Modelo Lineal Generalizado Bayesiano (BGLM) con
estructura autorregresiva de primer orden AR(1). Este enfoque difiere
sustancialmente de la metodología ECM-MARS al adoptar un paradigma
inferencial bayesiano completo, permitiendo cuantificar la incertidumbre
predictiva de manera integral y comparar modelos mediante criterios de
información predictiva.</p>
<div id="especificación-del-modelo-bayesiano-con-ar1" class="section level2">
<h2><strong>Especificación del Modelo Bayesiano con AR(1)</strong></h2>
<div id="estructura-del-modelo-completo" class="section level3">
<h3><strong>Estructura del Modelo Completo</strong></h3>
<p>Sea <span class="math inline">\(Y_t\)</span> la variable dependiente
y <span class="math inline">\(X_t\)</span> la variable independiente en
el tiempo <span class="math inline">\(t\)</span>. El modelo completo se
especifica como:</p>
<p><span class="math display">\[Y_{t,s} = \alpha + \beta_0 \cdot t_s +
\sum_{i=1}^{L} \beta_i X_{t-i,s} + \epsilon_t\]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(Y_{t,s}\)</span> es la variable
dependiente estandarizada: <span class="math inline">\((Y_t -
\mu_Y)/\sigma_Y\)</span></li>
<li><span class="math inline">\(t_s\)</span> es el índice temporal
estandarizado: <span class="math inline">\((t -
\mu_t)/\sigma_t\)</span></li>
<li><span class="math inline">\(X_{t-i,s}\)</span> son los rezagos
estandarizados de la variable independiente</li>
<li><span class="math inline">\(L\)</span> es el número máximo de
rezagos (por defecto <span class="math inline">\(L=3\)</span>)</li>
<li><span class="math inline">\(\epsilon_t\)</span> sigue un proceso
AR(1): <span class="math inline">\(\epsilon_t = \phi \epsilon_{t-1} +
\eta_t\)</span>, con <span class="math inline">\(\eta_t \sim N(0,
\sigma^2)\)</span></li>
</ul>
<p>La estandarización es crítica para la eficiencia del algoritmo NUTS<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> (No-U-Turn
Sampler), garantizando que todos los parámetros operen en escalas
comparables y evitando problemas de convergencia en el muestreador
Hamiltoniano.</p>
</div>
<div id="modelo-base-de-referencia" class="section level3">
<h3><strong>Modelo Base de Referencia</strong></h3>
<p>Como benchmark de comparación, se estima un modelo base que excluye
la información de la variable independiente:</p>
<p><span class="math display">\[Y_{t,s} = \alpha + \beta_0 \cdot t_s +
\epsilon_t\]</span></p>
<p>Este modelo captura únicamente la tendencia temporal y la estructura
autorregresiva intrínseca de <span class="math inline">\(Y\)</span>,
sirviendo como hipótesis nula efectiva contra la cual evaluar la
contribución predictiva de los rezagos de <span class="math inline">\(X\)</span>.</p>
</div>
<div id="especificación-de-priors" class="section level3">
<h3><strong>Especificación de Priors</strong></h3>
<p>Los priors se especifican en la escala estandarizada para mantener
consistencia:</p>
<ul>
<li><strong>Coeficientes de regresión</strong> (<span class="math inline">\(\beta_i\)</span>): <span class="math inline">\(\beta_i \sim N(0, 1)\)</span></li>
<li><strong>Intercepto</strong> (<span class="math inline">\(\alpha\)</span>): <span class="math inline">\(\alpha \sim t_3(0, 2.5)\)</span> (Student-t con 3
grados de libertad)</li>
<li><strong>Desviación estándar residual</strong> (<span class="math inline">\(\sigma\)</span>): <span class="math inline">\(\sigma \sim \text{Exponencial}(1)\)</span></li>
<li><strong>Coeficiente AR(1)</strong> (<span class="math inline">\(\phi\)</span>): Prior implícito uniforme en <span class="math inline">\((-1, 1)\)</span> para estacionariedad</li>
</ul>
<p>La elección de priors débilmente informativos<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> refleja un balance
entre regularización suave y flexibilidad para aprender de los datos. La
distribución Student-t para el intercepto proporciona robustez ante
valores atípicos, mientras que el prior exponencial para <span class="math inline">\(\sigma\)</span> garantiza positividad con cola
pesada.</p>
</div>
</div>
<div id="validación-cruzada-temporal-con-leave-future-out-lfo" class="section level2">
<h2><strong>Validación Cruzada Temporal con Leave-Future-Out
(LFO)</strong></h2>
<div id="implementación-del-rolling-origin-con-ventana-deslizante" class="section level3">
<h3><strong>Implementación del Rolling-Origin con Ventana
Deslizante</strong></h3>
<p>A diferencia de la validación cruzada tradicional que viola el
principio de causalidad temporal, implementamos Leave-Future-Out (LFO)
con ventana deslizante (<em>sliding window</em>). Este esquema respeta
estrictamente el ordenamiento temporal y simula el contexto real de
pronóstico prospectivo.</p>
<p>El procedimiento se estructura así:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Inicialización</strong>: El conjunto de entrenamiento
inicial comprende el 70% de los datos o un mínimo de 90 observaciones,
lo que sea mayor.</p></li>
<li><p><strong>Horizonte de prueba</strong>: Cada fold evalúa <span class="math inline">\(h = 12\)</span> meses hacia adelante, simulando
pronósticos anuales.</p></li>
<li><p><strong>Paso entre folds</strong>: El origen se desplaza 12 meses
entre evaluaciones sucesivas.</p></li>
<li><p><strong>Ventana deslizante</strong>: El tamaño del conjunto de
entrenamiento permanece constante<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>, descartando observaciones antiguas al
incorporar nuevas. Esto contrasta con la ventana expansiva donde el
conjunto de entrenamiento crece monotónicamente.</p></li>
</ol>
<p>La ventaja de la ventana deslizante radica en su sensibilidad a
cambios de régimen y su capacidad de adaptación a dinámicas no
estacionarias en sentido amplio. Mientras que una ventana expansiva
asume parámetros constantes a lo largo de toda la historia, la ventana
deslizante reconoce que las relaciones económicas pueden evolucionar,
manteniendo solo la “memoria reciente” más relevante para el
pronóstico.</p>
</div>
<div id="criterios-de-evaluación-predictiva" class="section level3">
<h3><strong>Criterios de Evaluación Predictiva</strong></h3>
<p>Para cada fold <span class="math inline">\(k\)</span>, comparamos el
desempeño predictivo del modelo completo contra el modelo base mediante
dos criterios complementarios:</p>
<div id="expected-log-predictive-density-elpd" class="section level4">
<h4><strong>Expected Log Predictive Density (ELPD)</strong></h4>
<p>El ELPD<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> cuantifica la densidad predictiva
logarítmica esperada para nuevas observaciones:</p>
<p><span class="math display">\[\text{ELPD}_k = \sum_{t \in
\text{test}_k} \log \int p(y_t | \theta) p(\theta |
\text{datos}_{\text{train},k}) d\theta\]</span></p>
<p>En la práctica, aproximamos esta integral mediante el estimador
log-sum-exp sobre las muestras posteriores:</p>
<p><span class="math display">\[\widehat{\text{ELPD}}_k = \sum_{t \in
\text{test}_k} \log \left( \frac{1}{S} \sum_{s=1}^S p(y_t |
\theta^{(s)}) \right)\]</span></p>
<p>donde <span class="math inline">\(\theta^{(s)}\)</span> son las
muestras posteriores y <span class="math inline">\(S\)</span> es el
número de iteraciones post-warmup.</p>
<p>La diferencia <span class="math inline">\(\Delta\text{ELPD}_k =
\text{ELPD}_{k,\text{full}} - \text{ELPD}_{k,\text{base}}\)</span> mide
la ganancia en capacidad predictiva. Un <span class="math inline">\(\Delta\text{ELPD} &gt; 0\)</span> indica que el
modelo completo asigna mayor probabilidad a los datos observados fuera
de muestra.</p>
</div>
<div id="root-mean-square-error-rmse-y-métricas-clásicas" class="section level4">
<h4><strong>Root Mean Square Error (RMSE) y Métricas
Clásicas</strong></h4>
<p>Complementamos el ELPD con métricas tradicionales en la escala
original de las variables:</p>
<ul>
<li><strong>RMSE</strong>: <span class="math inline">\(\sqrt{\frac{1}{n_{\text{test}}} \sum_{t} (y_t -
\hat{y}_t)^2}\)</span></li>
<li><strong>MAE</strong>: <span class="math inline">\(\frac{1}{n_{\text{test}}} \sum_{t} |y_t -
\hat{y}_t|\)</span></li>
<li><strong>sMAPE</strong>: <span class="math inline">\(\frac{100}{n_{\text{test}}} \sum_{t} \frac{2|y_t -
\hat{y}_t|}{|y_t| + |\hat{y}_t|}\)</span></li>
<li><strong>R²</strong>: <span class="math inline">\(1 - \frac{\sum_t
(y_t - \hat{y}_t)^2}{\sum_t (y_t - \bar{y})^2}\)</span> (protegido
contra <span class="math inline">\(SST \approx 0\)</span>)</li>
</ul>
<p>donde <span class="math inline">\(\hat{y}_t\)</span> es la media
posterior de las predicciones, obtenida mediante
<code>posterior_epred()</code> y transformada de vuelta a la escala
original.</p>
</div>
</div>
<div id="criterio-de-victoria-por-fold" class="section level3">
<h3><strong>Criterio de Victoria por Fold</strong></h3>
<p>Un modelo completo “gana” en el fold <span class="math inline">\(k\)</span> si y solo si:</p>
<p><span class="math display">\[\begin{cases}
\Delta\text{ELPD}_k &gt; 0 &amp; \text{(mejor densidad predictiva)} \\
\Delta\text{RMSE}_k &lt; 0 &amp; \text{(menor error cuadrático)}
\end{cases}\]</span></p>
<p>Este criterio dual exige superioridad tanto en términos
probabilísticos (ELPD) como determinísticos (RMSE), evitando victorias
espurias por mejoras en una sola dimensión.</p>
</div>
</div>
<div id="inferencia-bayesiana-con-hamiltonian-monte-carlo" class="section level2">
<h2><strong>Inferencia Bayesiana con Hamiltonian Monte
Carlo</strong></h2>
<div id="configuración-del-muestreador-nuts" class="section level3">
<h3><strong>Configuración del Muestreador NUTS</strong></h3>
<p>La inferencia se realiza mediante el algoritmo NUTS<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> implementado en Stan a
través de <code>brms</code> con backend <code>cmdstanr</code>. Los
parámetros de muestreo se calibran para garantizar convergencia
robusta:</p>
<ul>
<li><strong>Cadenas</strong>: 4 cadenas independientes</li>
<li><strong>Iteraciones totales</strong>: 1500 por cadena</li>
<li><strong>Warmup</strong>: 750 iteraciones (50% para adaptación)</li>
<li><strong>Adapt delta</strong>: 0.95 (reduce pasos divergentes)</li>
<li><strong>Max treedepth</strong>: 12 (evita truncamiento prematuro del
árbol)</li>
</ul>
<p>La paralelización se implementa a nivel de cadenas
(<code>parallel_chains = 4</code>), no dentro de cada cadena, para
mantener la eficiencia del muestreador sin sobresuscripción del CPU.</p>
</div>
<div id="diagnósticos-de-convergencia" class="section level3">
<h3><strong>Diagnósticos de Convergencia</strong></h3>
<p>Aunque no se reportan explícitamente en el código de producción por
eficiencia, los diagnósticos estándar incluyen:</p>
<ul>
<li><strong><span class="math inline">\(\hat{R}\)</span>
(Rhat)</strong>: Debe ser <span class="math inline">\(&lt; 1.01\)</span>
para todos los parámetros</li>
<li><strong>ESS (Effective Sample Size)</strong>: Bulk-ESS y Tail-ESS
<span class="math inline">\(&gt; 400\)</span> por cadena</li>
<li><strong>Divergencias</strong>: Idealmente 0; pocas divergencias
(&lt;1%) pueden ser tolerables</li>
<li><strong>BFMI (Bayesian Fraction of Missing Information)</strong>:
<span class="math inline">\(&gt; 0.2\)</span> indica buen
comportamiento</li>
</ul>
</div>
</div>
<div id="determinación-de-estabilidad-temporal-y-soporte" class="section level2">
<h2><strong>Determinación de Estabilidad Temporal y
Soporte</strong></h2>
<div id="métrica-de-soporte" class="section level3">
<h3><strong>Métrica de Soporte</strong></h3>
<p>Definimos el soporte como:</p>
<p><span class="math display">\[\text{support} =
\frac{\text{folds\_pass}}{\text{folds}}\]</span></p>
<p>donde <code>folds_pass</code> cuenta los folds donde el modelo
completo satisface el criterio dual de victoria. Esta métrica cuantifica
la consistencia temporal del poder predictivo.</p>
</div>
<div id="umbrales-de-robustez" class="section level3">
<h3><strong>Umbrales de Robustez</strong></h3>
<p>Establecemos dos niveles de confianza:</p>
<ul>
<li><strong>Umbral estricto</strong>: support <span class="math inline">\(\geq 0.70\)</span> con mínimo 5 folds válidos</li>
<li><strong>Umbral moderado</strong>: support <span class="math inline">\(\geq 0.60\)</span> con mínimo 5 folds válidos</li>
</ul>
<p>El requisito de un mínimo absoluto de folds previene falsos positivos
por denominadores pequeños (e.g., 1/1 = 100% support no constituye
evidencia robusta).</p>
</div>
<div id="interpretación-del-soporte" class="section level3">
<h3><strong>Interpretación del Soporte</strong></h3>
<p>Un soporte alto indica que la relación predictiva persiste a través
de diferentes regímenes temporales. Valores de soporte:</p>
<ul>
<li><strong>0.80-1.00</strong>: Relación muy estable, robusta a cambios
de régimen</li>
<li><strong>0.60-0.79</strong>: Relación moderadamente estable, sensible
a algunas épocas</li>
<li><strong>0.40-0.59</strong>: Relación inestable, dependiente del
contexto temporal</li>
<li><strong>&lt; 0.40</strong>: Relación espuria o altamente específica
a períodos particulares</li>
</ul>
</div>
</div>
<div id="análisis-comparativo-con-metodología-ecm-mars" class="section level2">
<h2><strong>Análisis Comparativo con Metodología ECM-MARS</strong></h2>
<div id="diferencias-fundamentales" class="section level3">
<h3><strong>Diferencias Fundamentales</strong></h3>
<table>
<colgroup>
<col width="22%" />
<col width="25%" />
<col width="52%" />
</colgroup>
<thead>
<tr class="header">
<th>Aspecto</th>
<th>ECM-MARS</th>
<th>GLM Bayesiano AR(1)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Paradigma</strong></td>
<td>Frecuentista con tests secuenciales</td>
<td>Bayesiano integral</td>
</tr>
<tr class="even">
<td><strong>Cointegración</strong></td>
<td>Requisito explícito (Engle-Granger/Johansen)</td>
<td>Implícita en estructura AR(1)</td>
</tr>
<tr class="odd">
<td><strong>No-linealidad</strong></td>
<td>MARS con splines adaptativos</td>
<td>Lineal en parámetros</td>
</tr>
<tr class="even">
<td><strong>Incertidumbre</strong></td>
<td>Errores estándar HAC</td>
<td>Distribución posterior completa</td>
</tr>
<tr class="odd">
<td><strong>Comparación</strong></td>
<td>Tests de significancia</td>
<td>ELPD + métricas predictivas</td>
</tr>
<tr class="even">
<td><strong>Complejidad</strong></td>
<td>Alta (múltiples pre-tests)</td>
<td>Moderada (modelo directo)</td>
</tr>
</tbody>
</table>
</div>
<div id="ventajas-del-enfoque-bayesiano" class="section level3">
<h3><strong>Ventajas del Enfoque Bayesiano</strong></h3>
<ol style="list-style-type: decimal">
<li><p><strong>Cuantificación integral de incertidumbre</strong>: Las
distribuciones posteriores capturan toda la incertidumbre paramétrica,
propagándola naturalmente a las predicciones.</p></li>
<li><p><strong>Comparación directa de modelos</strong>: El ELPD
proporciona una métrica unificada para comparar modelos no anidados sin
ajustes por multiplicidad.</p></li>
<li><p><strong>Robustez a violaciones de supuestos</strong>: Los priors
regularizadores y la estructura AR(1) acomodan desviaciones moderadas de
los supuestos clásicos.</p></li>
<li><p><strong>Interpretabilidad</strong>: Los intervalos de
credibilidad tienen interpretación probabilística directa, a diferencia
de los intervalos de confianza frecuentistas.</p></li>
</ol>
</div>
<div id="limitaciones-relativas" class="section level3">
<h3><strong>Limitaciones Relativas</strong></h3>
<ol style="list-style-type: decimal">
<li><p><strong>Costo computacional</strong>: El muestreo MCMC es órdenes
de magnitud más lento que la estimación por MCO/MARS.</p></li>
<li><p><strong>Sensibilidad a priors</strong>: En muestras pequeñas, la
elección de priors puede influir sustancialmente en los
resultados.</p></li>
<li><p><strong>Linealidad</strong>: La ausencia de términos no lineales
(splines) puede limitar la flexibilidad para capturar relaciones
complejas.</p></li>
</ol>
</div>
</div>
<div id="implementación-técnica-y-optimizaciones" class="section level2">
<h2><strong>Implementación Técnica y Optimizaciones</strong></h2>
<div id="gestión-de-memoria-y-paralelización" class="section level3">
<h3><strong>Gestión de Memoria y Paralelización</strong></h3>
<ul>
<li><p><strong>Paralelización por pares</strong>: Cada par <span class="math inline">\((X \to Y)\)</span> se procesa secuencialmente,
pero las cadenas MCMC dentro de cada modelo se paralelizan.</p></li>
<li><p><strong>Liberación de memoria</strong>: Los objetos de Stan se
liberan implícitamente tras cada fold mediante el recolector de basura
de R.</p></li>
<li><p><strong>Backend cmdstanr</strong>: Más eficiente que rstan para
modelos grandes, con mejor gestión de memoria y diagnósticos.</p></li>
</ul>
</div>
<div id="manejo-de-casos-degenerados" class="section level3">
<h3><strong>Manejo de Casos Degenerados</strong></h3>
<p>El código incluye salvaguardas para:</p>
<ul>
<li><strong>Varianza casi nula</strong>: Si <span class="math inline">\(\sigma_Y \approx 0\)</span> en el conjunto de
entrenamiento, el fold se omite.</li>
<li><strong>Errores de convergencia</strong>: Los modelos que fallan en
converger retornan <code>NULL</code> y se excluyen del análisis.</li>
<li><strong>Log-verosimilitudes indefinidas</strong>: Se verifican
valores finitos antes de calcular ELPD.</li>
</ul>
</div>
</div>
<div id="pseudocódigo-del-pipeline-completo" class="section level2">
<h2><strong>Pseudocódigo del Pipeline Completo</strong></h2>
<pre><code>PARA cada par (X, Y) en {producción × circulación} × {2 direcciones}:
  1. Construir matriz con Y, X, y lags(X, 1:L)
  2. Eliminar filas con valores faltantes
  
  PARA cada fold en rolling_splits(sliding_window):
    3. Dividir en train/test
    4. Estandarizar variables usando estadísticos del train
    5. Ajustar modelo_base: Y_s ~ 1 + t_s + AR(1)
    6. Ajustar modelo_full: Y_s ~ 1 + t_s + X_lags + AR(1)
    7. Calcular ELPD para ambos modelos en test
    8. Generar predicciones puntuales (posterior_epred)
    9. Transformar predicciones a escala original
    10. Computar métricas (RMSE, MAE, sMAPE, R²)
    11. Determinar victoria: (ΔELPD &gt; 0) ∧ (ΔRMSE &lt; 0)
  
  12. Calcular support = wins / total_folds
  13. Promediar métricas across folds

14. Ranking por (support DESC, ΔELPD DESC, ΔRMSE ASC)
15. Filtrar ganadores por umbrales de support
16. Exportar resultados y visualizaciones</code></pre>
</div>
<div id="notas-técnicas-y-consideraciones-especiales" class="section level2">
<h2><strong>Notas Técnicas y Consideraciones Especiales</strong></h2>
<div id="escalamiento-y-estabilidad-numérica" class="section level3">
<h3><strong>Escalamiento y Estabilidad Numérica</strong></h3>
<p>El escalamiento por fold (no global) es crucial porque:</p>
<ol style="list-style-type: decimal">
<li>Las estadísticas de normalización deben calcularse solo con datos
del train para evitar <em>data leakage</em><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></li>
<li>La escala de las variables puede cambiar sustancialmente entre
ventanas temporales</li>
<li>NUTS requiere que todos los parámetros operen en escalas <span class="math inline">\(\mathcal{O}(1)\)</span> para eficiencia</li>
</ol>
</div>
<div id="interpretación-de-métricas-negativas" class="section level3">
<h3><strong>Interpretación de Métricas Negativas</strong></h3>
<p>Es posible obtener <span class="math inline">\(R^2 &lt; 0\)</span> en
evaluación fuera de muestra cuando el modelo predice peor que la media
muestral. Esto no indica error de cálculo sino genuino mal desempeño
predictivo. De manera similar, ratios RMSE &gt; 1 indican que el modelo
completo empeora las predicciones respecto al baseline.</p>
</div>
<div id="extensiones-potenciales" class="section level3">
<h3><strong>Extensiones Potenciales</strong></h3>
<p>El framework actual admite varias extensiones naturales:</p>
<ul>
<li><strong>Heterocedasticidad</strong>: Modelar <span class="math inline">\(\sigma_t\)</span> como función del tiempo o
covariables</li>
<li><strong>Mezcla de expertos</strong>: Múltiples componentes AR con
pesos variables</li>
<li><strong>No-linealidad</strong>: Splines o funciones base mediante
<code>s()</code> en <code>brms</code></li>
<li><strong>Efectos aleatorios</strong>: Estructura jerárquica para
múltiples series</li>
<li><strong>Pronóstico multi-paso</strong>: Extender más allá de
one-step-ahead</li>
</ul>
</div>
</div>
<div id="conclusiones-metodológicas" class="section level2">
<h2><strong>Conclusiones Metodológicas</strong></h2>
<p>La metodología GLM Bayesiana con AR(1) ofrece un marco robusto y
principiado para evaluar relaciones predictivas entre variables
económicas. A diferencia del enfoque ECM-MARS que requiere validación
secuencial de múltiples supuestos (estacionariedad, cointegración,
velocidad de ajuste), el modelo bayesiano integra toda la incertidumbre
en un framework unificado.</p>
<p>Los resultados sugieren que las relaciones más robustas (support &gt;
0.70) corresponden típicamente a pares donde la teoría económica predice
causalidad fuerte, mientras que relaciones con support moderado
(0.60-0.70) pueden reflejar canales de transmisión indirectos o
dependientes del régimen económico vigente.</p>
<p>La evaluación dual mediante ELPD y RMSE garantiza que los modelos
seleccionados no solo ajusten bien en términos de error cuadrático sino
que también capturen adecuadamente la estructura probabilística de los
datos. Esta doble exigencia filtra efectivamente relaciones espurias que
podrían parecer prometedoras bajo un solo criterio.</p>
<hr />
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>NUTS (No-U-Turn Sampler) es una extensión adaptativa del
algoritmo Hamiltonian Monte Carlo que ajusta automáticamente la longitud
de las trayectorias para maximizar la eficiencia del muestreo sin
requerir tuning manual del número de pasos leapfrog.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Los priors débilmente informativos proporcionan
regularización suave sin imponer creencias fuertes a priori. En el
límite de datos abundantes, su influencia se desvanece, recuperando
estimaciones similares a máxima verosimilitud.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>El tamaño constante del conjunto de entrenamiento en
sliding window garantiza que todos los folds tengan poder estadístico
comparable, evitando el sesgo hacia folds tardíos que ocurre con
ventanas expansivas.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>ELPD (Expected Log Predictive Density) es el criterio de
evaluación predictiva fundamental en estadística bayesiana, generalizado
por WAIC y LOO-CV. Mide la capacidad del modelo para asignar alta
probabilidad a nuevas observaciones.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>El algoritmo NUTS elimina la necesidad de ajustar
manualmente el número de pasos en HMC mediante un criterio de parada
basado en “U-turns” en el espacio de parámetros, donde la trayectoria
comienza a retroceder hacia su origen.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Data leakage ocurre cuando información del conjunto de
prueba contamina el proceso de entrenamiento, inflando artificialmente
las métricas de desempeño. El escalamiento con estadísticas globales
constituiría una forma sutil pero perniciosa de leakage.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
